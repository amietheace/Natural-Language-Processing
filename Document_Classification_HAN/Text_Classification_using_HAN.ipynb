{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_using_HAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accANDgQMZx4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### To Upload the data from mydrive to this notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMhC8b4QMTYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1taGXUsMgGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8be4c316-4fc0-4ba0-f00c-3d1b254e2ac0"
      },
      "source": [
        "link1 = 'https://drive.google.com/open?id=18PSgJ2wCNkwr9-DH-oWlsRmIUuCMDMde'\n",
        "fluff, id_train_unlabled = link1.split('=')\n",
        "print (id_train_unlabled) # Verify that you have everything after '='\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18PSgJ2wCNkwr9-DH-oWlsRmIUuCMDMde\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO4QZK1WMx7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_train_unlabled}) \n",
        "downloaded.GetContentFile('train_unlabled.tsv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOBS0LndM2Ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbceee91-2523-4506-c34d-51e939e658ea"
      },
      "source": [
        "link2 = 'https://drive.google.com/open?id=1KgxQWhq6L8IqcQRuvW-OQIDH6iuq4Lo9'\n",
        "fluff, id_train_labled = link2.split('=')\n",
        "print (id_train_labled) # Verify that you have everything after '='\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1KgxQWhq6L8IqcQRuvW-OQIDH6iuq4Lo9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAMbTUt6M5Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_train_labled}) \n",
        "downloaded.GetContentFile('train_labled.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCGL3kblM_ki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a329dba-20b1-4019-f549-f81387b273da"
      },
      "source": [
        "link3 = 'https://drive.google.com/open?id=1z56Wba5iVO9RYuU4NbnHtVVkRW4YfaT8'\n",
        "fluff, id_test = link3.split('=')\n",
        "print (id_test) # Verify that you have everything after '='"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1z56Wba5iVO9RYuU4NbnHtVVkRW4YfaT8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7ZZlbaNDtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_test}) \n",
        "downloaded.GetContentFile('test.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5RkHrqyNHv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "370c95dd-6bfb-44e7-8abd-d140eda2b7f2"
      },
      "source": [
        "link4 = 'https://drive.google.com/open?id=1cTo4HOTu3M3bc-ve7ImPiK4CCbOYnGcO'\n",
        "fluff, id_sub = link4.split('=')\n",
        "print (id_sub) # Verify that you have everything after '='\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1cTo4HOTu3M3bc-ve7ImPiK4CCbOYnGcO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT2HL-p-NMp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_sub}) \n",
        "downloaded.GetContentFile('sub.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuGUqN9rNQpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "8bb2051d-95a4-4823-eae5-f69ad18a0dd2"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-17 10:58:58--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-07-17 10:58:58--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-07-17 10:58:59--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  18.5MB/s    in 43s     \n",
            "\n",
            "2019-07-17 10:59:42 (19.2 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoK5M4UKNbRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HzkMYEdODGt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "This example applies the HAN classifier to Kaggle's IMDB\n",
        "review dataset. The goal is to predict whether a review is\n",
        "positive (5 star rating >=3) or negative (otherwise)\n",
        "\n",
        "## Importing some required library and functions for data processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_TiZnRiNrdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d41c77de-c3a1-4227-c611-fa03eee07876"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2dgS3wJObvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a logger to provide info on the state of the\n",
        "# script\n",
        "stdout = logging.StreamHandler(sys.stdout)\n",
        "stdout.setFormatter(logging.Formatter(\n",
        "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "))\n",
        "logger = logging.getLogger('default')\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.addHandler(stdout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL6100GPOkHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9df50f4f-112c-4c5e-a66a-adcc6559dc53"
      },
      "source": [
        "#####################################################\n",
        "# Pre processing                                    #\n",
        "#####################################################\n",
        "logger.info(\"Pre-processsing data.\")\n",
        "\n",
        "# Load Kaggle's IMDB example data\n",
        "data = pd.read_csv('train_labled.tsv', sep='\\t')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-17 11:01:02,434 - default - INFO - Pre-processsing data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "I0717 11:01:02.434939 140345455339392 <ipython-input-15-404f3efd7689>:1] Pre-processsing data.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp971k7gO_gr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "dba00b6c-33b2-4ecb-d5c4-22a64636b844"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5814_8</td>\n",
              "      <td>1</td>\n",
              "      <td>With all this stuff going down at the moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2381_9</td>\n",
              "      <td>1</td>\n",
              "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7759_3</td>\n",
              "      <td>0</td>\n",
              "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3630_4</td>\n",
              "      <td>0</td>\n",
              "      <td>It must be assumed that those who praised this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9495_8</td>\n",
              "      <td>1</td>\n",
              "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  sentiment                                             review\n",
              "0  5814_8          1  With all this stuff going down at the moment w...\n",
              "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
              "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
              "3  3630_4          0  It must be assumed that those who praised this...\n",
              "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ0A4LOGPIkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do some basic cleaning of the review text\n",
        "def remove_quotations(text):\n",
        "    \"\"\"\n",
        "    Remove quotations and slashes from the dataset.\n",
        "    \"\"\"\n",
        "    text = re.sub(r\"\\\\\", \"\", text)\n",
        "    text = re.sub(r\"\\'\", \"\", text)\n",
        "    text = re.sub(r\"\\\"\", \"\", text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23D25QxDPVuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    \"\"\"\n",
        "    Very, very raw parser to remove HTML tags from\n",
        "    texts.\n",
        "    \"\"\"\n",
        "    tags_regex = re.compile(r'<.*?>')\n",
        "    return tags_regex.sub('', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPEWqXfBPedh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['review'] = data['review'].apply(remove_quotations)\n",
        "data['review'] = data['review'].apply(remove_html)\n",
        "data['review'] = data['review'].apply(lambda x: x.strip().lower())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ImvXWTgPl8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the data and the sentiment\n",
        "reviews = data['review'].values\n",
        "target = data['sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vNCI6xEPtXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "1beeb565-7fe5-4c2e-bad8-d8527676083e"
      },
      "source": [
        "reviews[5:]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['i dont know why people think this is such a bad movie. its got a pretty good plot, some good action, and the change of location for harry does not hurt either. sure some of its offensive and gratuitous but this is not the only movie like that. eastwood is in good form as dirty harry, and i liked pat hingle in this movie as the small town cop. if you liked dirty harry, then you should see this one, its a lot better than the dead pool. 4/5',\n",
              "       'this movie could have been very good, but comes up way short. cheesy special effects and so-so acting. i could have looked past that if the story wasnt so lousy. if there was more of a background story, it would have been better. the plot centers around an evil druid witch who is linked to this woman who gets migraines. the movie drags on and on and never clearly explains anything, it just keeps plodding on. christopher walken has a part, but it is completely senseless, as is most of the movie. this movie had potential, but it looks like some really bad made for tv movie. i would avoid this movie.',\n",
              "       'i watched this video at a friends house. im glad i did not waste money buying this one. the video cover has a scene from the 1975 movie capricorn one. the movie starts out with several clips of rocket blow-ups, most not related to manned flight. sibrels smoking gun is a short video clip of the astronauts preparing a video broadcast. he edits in his own voice-over instead of letting us listen to what the crew had to say. the video curiously ends with a showing of the zapruder film. his claims about radiation, shielding, star photography, and others lead me to believe is he extremely ignorant or has some sort of ax to grind against nasa, the astronauts, or american in general. his science is bad, and so is this video.',\n",
              "       ...,\n",
              "       'guy is a loser. cant get girls, needs to build up, is picked on by stronger more successful guys, etc. seen it, saw it, moved on. id have to say that rob needs to move past the adam sandler part of his life. and get out of the adam sandler plots. there are two funny parts in the whole movie. i couldnt even finish the last 5 minutes. i was getting bored. the animal is an alright film. i do usually enjoy adam sandler films that have the same plot. but this was trying too hard to impress. the jokes are very old. so, trust me. this is not a film that most people could really get into. but some did, so ill be nice.3/10',\n",
              "       'this 30 minute documentary buñuel made in the early 1930s about one of spains poorest regions is, in my opinion, one of his weakest films. first, lets admit that 70 years later, spain is much richer than it was then (and when i say this, i fully admit that wealth can bring problems of its own, like excessive individualism and consumerism, though all in all wealth its a far better condition than the extreme poverty portrayed here). and if poverty receded in spain it was not exactly with the sort of socialism that buñuel favored, but with western european style capitalism. but one of the most shocking things about the movie is this: in one scene, the narrator chides that in school, children are taught the value of pi. teaching math to poor people, the horror!. buñuel shortsightedness is at its most glaring here, not realizing that it is access to the latest knowledge and technology what will help the poor overcome their situation. what is he proposing? that children are taught exactly what at school? doesnt buñuel understand that it is the lack of modern technology that has made them poor in comparison with other people?',\n",
              "       'i saw this movie as a child and it broke my heart! no other story had such a unfinished ending... i grew up on many great anime movies and this was one of my favourites, because it was so unusual - a story about unfairness, and cruelty, and loneliness, and life, and choices that cant be undone, and the need for others. chirin is made alone when the wolf kills his mother, but the wolf is alone, too, when chirin follows him into the mountain. the wolf doesnt kill the lamb, even though each night he says maybe ill eat you tomorrow. the tape of it i have is broken and degraded from age and use. i will repair it and watch the movie again someday and cry just as hard as i did as a child. stories like this, with this depth and feeling, and this intricacy of meaning, are very rare. it is a sad story, but ive never encountered any catharsis more beautifully made. i am glad i have seen this movie, and im glad i saw it as a child.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqYvRlT-PwOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f17458b6-33a6-488c-8144-1982e5399835"
      },
      "source": [
        "target[5:]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmaxNA_7QCkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a76e71bd-1f77-4095-e6b8-d46eba0fa1a8"
      },
      "source": [
        "len(reviews)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TIz6ViVQens",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1404874-5ddb-4ab3-a6b9-ec7d9371183d"
      },
      "source": [
        "len(target)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufae5DtQQngl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_WORDS_PER_SENT = 100\n",
        "MAX_SENT = 15\n",
        "MAX_VOC_SIZE = 20000\n",
        "GLOVE_DIM = 100\n",
        "TEST_SPLIT = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYcr6DriRlge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZarECFlSHsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "31adcb2f-b987-4496-b21d-67f6a30dd151"
      },
      "source": [
        "#####################################################\n",
        "# Tokenization                                      #\n",
        "#####################################################\n",
        "logger.info(\"Tokenization.\")\n",
        "\n",
        "# Build a Keras Tokenizer that can encode every token\n",
        "word_tokenizer = Tokenizer(num_words=MAX_VOC_SIZE)\n",
        "word_tokenizer.fit_on_texts(reviews)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-17 11:02:18,967 - default - INFO - Tokenization.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0717 11:02:18.967431 140345455339392 <ipython-input-27-5333471a0b96>:1] Tokenization.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yEZcsaSVTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct the input matrix. This should be a nd-array of\n",
        "# shape (n_samples, MAX_SENT, MAX_WORDS_PER_SENT).\n",
        "# We zero-pad this matrix (this does not influence\n",
        "# any predictions due to the attention mechanism.\n",
        "X = np.zeros((len(reviews), MAX_SENT, MAX_WORDS_PER_SENT), dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNkAMniSkLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, review in enumerate(reviews):\n",
        "    sentences = sent_tokenize(review)\n",
        "    tokenized_sentences = word_tokenizer.texts_to_sequences(\n",
        "        sentences\n",
        "    )\n",
        "    tokenized_sentences = pad_sequences(\n",
        "        tokenized_sentences, maxlen=MAX_WORDS_PER_SENT\n",
        "    )\n",
        "\n",
        "    pad_size = MAX_SENT - tokenized_sentences.shape[0]\n",
        "\n",
        "    if pad_size < 0:\n",
        "        tokenized_sentences = tokenized_sentences[0:MAX_SENT]\n",
        "    else:\n",
        "        tokenized_sentences = np.pad(\n",
        "            tokenized_sentences, ((0,pad_size),(0,0)),\n",
        "            mode='constant', constant_values=0\n",
        "        )\n",
        "\n",
        "    # Store this observation as the i-th observation in\n",
        "    # the data matrix\n",
        "    X[i] = tokenized_sentences[None, ...]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJZ7MX89ToQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the labels into a format Keras can handle\n",
        "y = to_categorical(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7v3f4VKUQPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We make a train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whENWenPUXI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "outputId": "1fcd4d76-eb19-483d-eecf-3c8ffc79c85a"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[    0,     0,     0, ...,  1657,    30,    29],\n",
              "        [    0,     0,     0, ...,    46,   129,   487],\n",
              "        [    0,     0,     0, ...,    32,   216,  2992],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,    93,     8,    49],\n",
              "        [    0,     0,     0, ...,   371,   375,   146],\n",
              "        [    0,     0,     0, ...,     0,     0,     0]],\n",
              "\n",
              "       [[    0,     0,     0, ...,  1201,  2795,   619],\n",
              "        [    0,     0,     0, ...,    28,  2485,  1961],\n",
              "        [    0,     0,     0, ...,   680,     9,  3805],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,  1127,    14,    38],\n",
              "        [    0,     0,     0, ...,   900,   784,   239],\n",
              "        [    0,     0,     0, ...,     0,   300,   159]],\n",
              "\n",
              "       [[    0,     0,     0, ...,     0,   529,    16],\n",
              "        [    0,     0,     0, ...,    65,    40,   477],\n",
              "        [    0,     0,     0, ...,   154,     8,  7102],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[    0,     0,     0, ...,    49,    37,     3],\n",
              "        [    0,     0,     0, ...,   120,     1, 13344],\n",
              "        [    0,     0,     0, ...,    94,    10,    92],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0]],\n",
              "\n",
              "       [[   11,    87,   149, ...,   972,  6999,    73],\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0]],\n",
              "\n",
              "       [[    0,     0,     0, ...,    55,     6,  2755],\n",
              "        [    0,     0,     0, ...,   318,   741,    86],\n",
              "        [    0,     0,     0, ...,    20,    13,   305],\n",
              "        ...,\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0],\n",
              "        [    0,     0,     0, ...,     0,     0,     0]]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIvWv6xrUkJr",
        "colab_type": "text"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgihGmq6UaaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "528c6b2b-268b-417c-d748-c5b84c4d90b9"
      },
      "source": [
        "# Word Embeddings                                   #\n",
        "#####################################################\n",
        "logger.info(\n",
        "    \"Creating embedding matrix using pre-trained GloVe vectors.\"\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-17 11:03:21,571 - default - INFO - Creating embedding matrix using pre-trained GloVe vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0717 11:03:21.571979 140345455339392 <ipython-input-33-cf82a7b6b8bc>:2] Creating embedding matrix using pre-trained GloVe vectors.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkWP74AAUxQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, we need to build the embedding matrix. For this we use\n",
        "# a pretrained (on the wikipedia corpus) 100-dimensional GloVe\n",
        "# model.\n",
        "\n",
        "# Load the embeddings from a file\n",
        "embeddings = {}\n",
        "with open('glove.6B.%dd.txt' % GLOVE_DIM, encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "\n",
        "        embeddings[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXR1jxLvVKgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a matrix to hold the word embeddings\n",
        "embedding_matrix = np.random.random(\n",
        "    (len(word_tokenizer.word_index) + 1, GLOVE_DIM)\n",
        ")\n",
        "\n",
        "# Let the padded indices map to zero-vectors. This will\n",
        "# prevent the padding from influencing the results\n",
        "embedding_matrix[0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTd15PtrVcow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop though all the words in the word_index and where possible\n",
        "# replace the random initalization with the GloVe vector.\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nxD5DvSWGo3",
        "colab_type": "text"
      },
      "source": [
        "## Now construct the Layers and Model\n",
        "\n",
        "### 1. Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfy9-VyfVqLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"containing custom Keras layers that use the attention mechanism.\"\"\"\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6f4Pyp8Wyra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionLayer(keras.layers.Layer):\n",
        "    def __init__(self, context_vector_length=100, **kwargs):\n",
        "        \"\"\"\n",
        "        An implementation of a attention layer. This layer\n",
        "        accepts a 3d Tensor (batch_size, time_steps, input_dim) and\n",
        "        applies a single layer attention mechanism in the time\n",
        "        direction (the second axis).\n",
        "        :param context_vector_lenght: (int) The size of the hidden context vector.\n",
        "            If set to 1 this layer reduces to a standard attention layer.\n",
        "        :param kwargs: Any argument that the baseclass Layer accepts.\n",
        "        \"\"\"\n",
        "        self.context_vector_length = context_vector_length\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[2]\n",
        "\n",
        "        # Add a weights layer for the\n",
        "        self.W = self.add_weight(\n",
        "            name='W', shape=(dim, self.context_vector_length),\n",
        "            initializer=keras.initializers.get('uniform'),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        self.u = self.add_weight(\n",
        "            name='context_vector', shape=(self.context_vector_length, 1),\n",
        "            initializer=keras.initializers.get('uniform'),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def _get_attention_weights(self, X):\n",
        "        \"\"\"\n",
        "        Computes the attention weights for each timestep in X\n",
        "        :param X: 3d-tensor (batch_size, time_steps, input_dim)\n",
        "        :return: 2d-tensor (batch_size, time_steps) of attention weights\n",
        "        \"\"\"\n",
        "        # Compute a time-wise stimulus, i.e. a stimulus for each\n",
        "        # time step. For this first compute a hidden layer of\n",
        "        # dimension self.context_vector_length and take the\n",
        "        # similarity of this layer with self.u as the stimulus\n",
        "        u_tw = K.tanh(K.dot(X, self.W))\n",
        "        tw_stimulus = K.dot(u_tw, self.u)\n",
        "\n",
        "        # Remove the last axis an apply softmax to the stimulus to\n",
        "        # get a probability.\n",
        "        tw_stimulus = K.reshape(tw_stimulus, (-1, tw_stimulus.shape[1]))\n",
        "        att_weights = K.softmax(tw_stimulus)\n",
        "\n",
        "        return att_weights\n",
        "\n",
        "    def call(self, X):\n",
        "        att_weights = self._get_attention_weights(X)\n",
        "\n",
        "        # Reshape the attention weights to match the dimensions of X\n",
        "        att_weights = K.reshape(att_weights, (-1, att_weights.shape[1], 1))\n",
        "        att_weights = K.repeat_elements(att_weights, X.shape[-1], -1)\n",
        "\n",
        "        # Multiply each input by its attention weights\n",
        "        weighted_input = keras.layers.Multiply()([X, att_weights])\n",
        "\n",
        "        # Sum in the direction of the time-axis.\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[2]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'context_vector_length': self.context_vector_length\n",
        "        }\n",
        "        base_config = super(AttentionLayer, self).get_config()\n",
        "        return {**base_config, **config}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDxkKZcWXwdX",
        "colab_type": "text"
      },
      "source": [
        "### 2. Model preperation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWhNXjeFXse8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import (\n",
        "    Dense, GRU, TimeDistributed, Input,\n",
        "    Embedding, Bidirectional, Lambda\n",
        ")\n",
        "from keras.models import Model\n",
        "# from keras_han.layers import AttentionLayer\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2clkq8GYGKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HAN(Model):\n",
        "    def __init__(\n",
        "            self, max_words, max_sentences, output_size,\n",
        "            embedding_matrix, word_encoding_dim=200,\n",
        "            sentence_encoding_dim=200, inputs=None,\n",
        "            outputs=None, name='han-for-docla'\n",
        "    ):\n",
        "        \"\"\"\n",
        "        A Keras implementation of Hierarchical Attention networks\n",
        "        for document classification.\n",
        "        :param max_words: The maximum number of words per sentence\n",
        "        :param max_sentences: The maximum number of sentences\n",
        "        :param output_size: The dimension of the last layer (i.e.\n",
        "            the number of classes you wish to predict)\n",
        "        :param embedding_matrix: The embedding matrix to use for\n",
        "            representing words\n",
        "        :param word_encoding_dim: The dimension of the GRU\n",
        "            layer in the word encoder.\n",
        "        :param sentence_encoding_dim: The dimension of the GRU\n",
        "            layer in the sentence encoder.\n",
        "        \"\"\"\n",
        "        self.max_words = max_words\n",
        "        self.max_sentences = max_sentences\n",
        "        self.output_size = output_size\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.word_encoding_dim = word_encoding_dim\n",
        "        self.sentence_encoding_dim = sentence_encoding_dim\n",
        "\n",
        "\n",
        "        in_tensor, out_tensor = self._build_network()\n",
        "\n",
        "        super(HAN, self).__init__(\n",
        "            inputs=in_tensor, outputs=out_tensor, name=name\n",
        "        )\n",
        "\n",
        "    def build_word_encoder(self, max_words, embedding_matrix, encoding_dim=200):\n",
        "        \"\"\"\n",
        "        Build the model that embeds and encodes in context the\n",
        "        words used in a sentence. The return model takes a tensor of shape\n",
        "        (batch_size, max_length) that represents a collection of sentences\n",
        "        and returns an encoded representation of these sentences.\n",
        "        :param max_words: (int) The maximum sentence length this model accepts\n",
        "        :param embedding_matrix: (2d array-like) A matrix with the i-th row\n",
        "            representing the embedding of the word represented by index i.\n",
        "        :param encoding_dim: (int, should be even) The dimension of the\n",
        "            bidirectional encoding layer. Half of the nodes are used in the\n",
        "            forward direction and half in the backward direction.\n",
        "        :return: Instance of keras.Model\n",
        "        \"\"\"\n",
        "        assert encoding_dim % 2 == 0, \"Embedding dimension should be even\"\n",
        "\n",
        "        vocabulary_size = embedding_matrix.shape[0]\n",
        "        embedding_dim = embedding_matrix.shape[1]\n",
        "\n",
        "        embedding_layer = Embedding(\n",
        "            vocabulary_size, embedding_dim,\n",
        "            weights=[embedding_matrix], input_length=max_words,\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "        sentence_input = Input(shape=(max_words,), dtype='int32')\n",
        "        embedded_sentences = embedding_layer(sentence_input)\n",
        "        encoded_sentences = Bidirectional(\n",
        "            GRU(int(encoding_dim / 2), return_sequences=True)\n",
        "        )(embedded_sentences)\n",
        "\n",
        "        return Model(\n",
        "            inputs=[sentence_input], outputs=[encoded_sentences], name='word_encoder'\n",
        "        )\n",
        "\n",
        "    def build_sentence_encoder(self, max_sentences, summary_dim, encoding_dim=200):\n",
        "        \"\"\"\n",
        "        Build the encoder that encodes the vector representation of\n",
        "        sentences in their context.\n",
        "        :param max_sentences: The maximum number of sentences that can be\n",
        "            passed. Use zero-padding to supply shorter sentences.\n",
        "        :param summary_dim: (int) The dimension of the vectors that summarizes\n",
        "            sentences. Should be equal to the encoding_dim of the word\n",
        "            encoder.\n",
        "        :param encoding_dim: (int, even) The dimension of the vector that\n",
        "            summarizes sentences in context. Half is used in forward direction,\n",
        "            half in backward direction.\n",
        "        :return: Instance of keras.Model\n",
        "        \"\"\"\n",
        "        assert encoding_dim % 2 == 0, \"Embedding dimension should be even\"\n",
        "\n",
        "        text_input = Input(shape=(max_sentences, summary_dim))\n",
        "        encoded_sentences = Bidirectional(\n",
        "            GRU(int(encoding_dim / 2), return_sequences=True)\n",
        "        )(text_input)\n",
        "        return Model(\n",
        "            inputs=[text_input], outputs=[encoded_sentences], name='sentence_encoder'\n",
        "        )\n",
        "\n",
        "    def _build_network(self):\n",
        "        \"\"\"\n",
        "        Build the graph that represents this network\n",
        "        :return: in_tensor, out_tensor, Tensors representing the input and output\n",
        "            of this network.\n",
        "        \"\"\"\n",
        "        in_tensor = Input(shape=(self.max_sentences, self.max_words))\n",
        "\n",
        "        word_encoder = self.build_word_encoder(\n",
        "            self.max_words, self.embedding_matrix, self.word_encoding_dim\n",
        "        )\n",
        "\n",
        "        word_rep = TimeDistributed(\n",
        "            word_encoder, name='word_encoder'\n",
        "        )(in_tensor)\n",
        "\n",
        "        # Sentence Rep is a 3d-tensor (batch_size, max_sentences, word_encoding_dim)\n",
        "        sentence_rep = TimeDistributed(\n",
        "            AttentionLayer(), name='word_attention'\n",
        "        )(word_rep)\n",
        "\n",
        "        doc_rep = self.build_sentence_encoder(\n",
        "            self.max_sentences, self.word_encoding_dim, self.sentence_encoding_dim\n",
        "        )(sentence_rep)\n",
        "\n",
        "        # We get the final representation by applying our attention mechanism\n",
        "        # to the encoded sentences\n",
        "        doc_summary = AttentionLayer(name='sentence_attention')(doc_rep)\n",
        "\n",
        "        out_tensor = Dense(\n",
        "            self.output_size, activation='softmax', name='class_prediction'\n",
        "        )(doc_summary)\n",
        "\n",
        "        return in_tensor, out_tensor\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'max_words': self.max_words,\n",
        "            'max_sentences': self.max_sentences,\n",
        "            'output_size': self.output_size,\n",
        "            'embedding_matrix': self.embedding_matrix,\n",
        "            'word_encoding_dim': self.word_encoding_dim,\n",
        "            'sentence_encoding_dim': self.sentence_encoding_dim,\n",
        "            'base_config': super(HAN, self).get_config()\n",
        "        }\n",
        "\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config, custom_objects=None):\n",
        "        \"\"\"\n",
        "        Keras' API isn't really extendible at this point\n",
        "        therefore we need to use a bit hacky solution to\n",
        "        be able to correctly reconstruct the HAN model\n",
        "        from a config. This therefore does not reconstruct\n",
        "        a instance of HAN model, but actually a standard\n",
        "        Keras model that behaves exactly the same.\n",
        "        \"\"\"\n",
        "        base_config = config.pop('base_config')\n",
        "\n",
        "        return Model.from_config(\n",
        "            base_config, custom_objects=custom_objects\n",
        "        )\n",
        "\n",
        "    def predict_sentence_attention(self, X):\n",
        "        \"\"\"\n",
        "        For a given set of texts predict the attention\n",
        "        weights for each sentence.\n",
        "        :param X: 3d-tensor, similar to the input for predict\n",
        "        :return: 2d array (num_obs, max_sentences) containing\n",
        "            the attention weights for each sentence\n",
        "        \"\"\"\n",
        "        att_layer = self.get_layer('sentence_attention')\n",
        "        prev_tensor = att_layer.input\n",
        "\n",
        "        # Create a temporary dummy layer to hold the\n",
        "        # attention weights tensor\n",
        "        dummy_layer = Lambda(\n",
        "            lambda x: att_layer._get_attention_weights(x)\n",
        "        )(prev_tensor)\n",
        "\n",
        "        return Model(self.input, dummy_layer).predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBpzvz0QdMUe",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4unVyilic7eI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "46c26b43-eab6-47ac-fc5b-75daf10a1789"
      },
      "source": [
        "logger.info(\"Training the model.\")\n",
        "\n",
        "\n",
        "han_model = HAN(\n",
        "    MAX_WORDS_PER_SENT, MAX_SENT, 2, embedding_matrix,\n",
        "    word_encoding_dim=100, sentence_encoding_dim=100\n",
        ")\n",
        "\n",
        "han_model.summary()\n",
        "\n",
        "han_model.compile(\n",
        "    optimizer='adagrad', loss='categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-17 11:04:30,743 - default - INFO - Training the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0717 11:04:30.743460 140345455339392 <ipython-input-41-01420d199258>:1] Training the model.\n",
            "W0717 11:04:30.754431 140345455339392 module_wrapper.py:136] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/module_wrapper.py:163: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0717 11:04:32.658465 140345455339392 module_wrapper.py:136] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/module_wrapper.py:163: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 15, 100)           0         \n",
            "_________________________________________________________________\n",
            "word_encoder (TimeDistribute (None, 15, 100, 100)      8195700   \n",
            "_________________________________________________________________\n",
            "word_attention (TimeDistribu (None, 15, 100)           10100     \n",
            "_________________________________________________________________\n",
            "sentence_encoder (Model)     (None, 15, 100)           45300     \n",
            "_________________________________________________________________\n",
            "sentence_attention (Attentio (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "class_prediction (Dense)     (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 8,261,402\n",
            "Trainable params: 111,002\n",
            "Non-trainable params: 8,150,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL1blV-BdgRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "c66ad08e-69f3-464a-e371-23cae2659dac"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "han_model.fit(\n",
        "    X_train, y_train, batch_size=20, epochs=10,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 11:10:31.769526 140345455339392 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1251: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 842s 42ms/step - loss: 0.4124 - acc: 0.8028 - val_loss: 0.3400 - val_acc: 0.8548\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 838s 42ms/step - loss: 0.3162 - acc: 0.8658 - val_loss: 0.3179 - val_acc: 0.8636\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 838s 42ms/step - loss: 0.2958 - acc: 0.8753 - val_loss: 0.3118 - val_acc: 0.8662\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 836s 42ms/step - loss: 0.2794 - acc: 0.8839 - val_loss: 0.3058 - val_acc: 0.8648\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 841s 42ms/step - loss: 0.2689 - acc: 0.8883 - val_loss: 0.2999 - val_acc: 0.8714\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 844s 42ms/step - loss: 0.2580 - acc: 0.8937 - val_loss: 0.2994 - val_acc: 0.8682\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 842s 42ms/step - loss: 0.2495 - acc: 0.8992 - val_loss: 0.3005 - val_acc: 0.8736\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 840s 42ms/step - loss: 0.2414 - acc: 0.9016 - val_loss: 0.2963 - val_acc: 0.8732\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 846s 42ms/step - loss: 0.2332 - acc: 0.9071 - val_loss: 0.2986 - val_acc: 0.8736\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 852s 43ms/step - loss: 0.2249 - acc: 0.9111 - val_loss: 0.2967 - val_acc: 0.8742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa45f995c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdavoGtIjIN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}